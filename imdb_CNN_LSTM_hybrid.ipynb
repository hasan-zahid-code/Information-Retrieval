{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0I5cLw74j0L",
        "outputId": "5f9317b0-f1a0-4a7f-9ca1-e4961d7cff85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOtSsxf2xaU_"
      },
      "source": [
        "# IMDB Sentiment Analysis using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ6YZzozxaVB"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6hGr8z0UxaVC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-lA_wNNxaVD"
      },
      "source": [
        "## Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu-pOXzoxaVD",
        "outputId": "51eefe42-83d4-4699-f9e1-708e219adf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                             review  sentiment\n",
            "0           0  i went and saw this movie last night after bei...          1\n",
            "1           1  actor turned director bill paxton follows up h...          1\n",
            "2           2  as a recreational golfer with some knowledge o...          1\n",
            "3           3  i saw this film in a sneak preview and it is d...          1\n",
            "4           4  bill paxton has taken the true story of the 19...          1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/movie_reviews.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQT3gTm260PH",
        "outputId": "3ef1f34d-4406-43d7-87e6-6538f015ef75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm09aQ4PxaVF"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9LPqZhW0xaVF"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "# removing the html tags\n",
        "def clean_html(text):\n",
        "    clean=re.compile('<.*?>')\n",
        "    cleantext=re.sub(clean,'',text)\n",
        "    return cleantext\n",
        "\n",
        "# first round of cleaning\n",
        "def clean_text1(text):\n",
        "    text=text.lower()\n",
        "    text=re.sub('\\[.*?\\]','',text)\n",
        "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
        "    text=re.sub('\\w*\\d\\w*','',text)\n",
        "    return text\n",
        "\n",
        "# second round of cleaning\n",
        "def clean_text2(text):\n",
        "    text=re.sub('[''\"\",,,]','',text)\n",
        "    text=re.sub('\\n','',text)\n",
        "    return text\n",
        "\n",
        "cleaned_html=lambda x:clean_html(x)\n",
        "cleaned1=lambda x:clean_text1(x)\n",
        "cleaned2=lambda x:clean_text2(x)\n",
        "\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned_html))\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned1))\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Po7GWPxaVF"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WG2xtTNuKpcv"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
        "tokenizer.fit_on_texts(data['review'].values)\n",
        "X = tokenizer.texts_to_sequences(data['review'].values)\n",
        "X = pad_sequences(X,maxlen=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyu95uejxaVG",
        "outputId": "81b098fd-2ebc-42b7-fffc-9bd79ce0ff4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 600, 128)          640000    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 600, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 600, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 300, 64)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 19200)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               4915456   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5580610 (21.29 MB)\n",
            "Trainable params: 5580610 (21.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, SpatialDropout1D, Embedding, Dense, Dropout, LSTM\n",
        "\n",
        "# Define the model\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(5000, 128, input_length=X.shape[1]))  # Embedding layer\n",
        "model_cnn.add(SpatialDropout1D(0.4))  # Spatial Dropout for regularization\n",
        "model_cnn.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))  # LSTM layer \n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))  # Convolutional layer\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))  # Pooling layer\n",
        "model_cnn.add(Flatten())  # Flatten layer to convert 2D to 1D\n",
        "model_cnn.add(Dense(256, activation='relu'))  # Fully connected layer\n",
        "model_cnn.add(Dropout(0.5))  # Dropout for regularization\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model_cnn.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uRaASZHxaVH"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1O9Lc3fOxaVH"
      },
      "outputs": [],
      "source": [
        "Y=pd.get_dummies(data['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = tts(X,Y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hcs8k1kxaVI"
      },
      "source": [
        "## Running the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OHvTFFdexaVI",
        "outputId": "311b35a2-df45-431f-867d-ff7abc9e13a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 54s 75ms/step - loss: 0.3812 - accuracy: 0.8158 - val_loss: 0.2542 - val_accuracy: 0.8958\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.2310 - accuracy: 0.9097 - val_loss: 0.2474 - val_accuracy: 0.8983\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 12s 20ms/step - loss: 0.1858 - accuracy: 0.9286 - val_loss: 0.2604 - val_accuracy: 0.8936\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.1471 - accuracy: 0.9450 - val_loss: 0.2693 - val_accuracy: 0.8949\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.1058 - accuracy: 0.9612 - val_loss: 0.3183 - val_accuracy: 0.8930\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 0.3689 - val_accuracy: 0.8898\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 0.4513 - val_accuracy: 0.8894\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.4531 - val_accuracy: 0.8872\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0385 - accuracy: 0.9862 - val_loss: 0.5052 - val_accuracy: 0.8870\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.5110 - val_accuracy: 0.8842\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d946745f520>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 64\n",
        "model_cnn.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test,Y_test), verbose = True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
