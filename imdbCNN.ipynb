{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0I5cLw74j0L",
        "outputId": "36cbeafb-a06b-4f78-ceb0-13f956debbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOtSsxf2xaU_"
      },
      "source": [
        "# IMDB Sentiment Analysis using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ6YZzozxaVB"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6hGr8z0UxaVC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-lA_wNNxaVD"
      },
      "source": [
        "## Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu-pOXzoxaVD",
        "outputId": "a0ab4739-ec6b-454f-92ea-944009404aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                             review  sentiment\n",
            "0           0  i went and saw this movie last night after bei...          1\n",
            "1           1  actor turned director bill paxton follows up h...          1\n",
            "2           2  as a recreational golfer with some knowledge o...          1\n",
            "3           3  i saw this film in a sneak preview and it is d...          1\n",
            "4           4  bill paxton has taken the true story of the 19...          1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/movie_reviews.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQT3gTm260PH",
        "outputId": "ba520c51-f41b-49dd-fb65-2b9bde65aa43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of the data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm09aQ4PxaVF"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9LPqZhW0xaVF"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "# removing the html tags\n",
        "def clean_html(text):\n",
        "    clean=re.compile('<.*?>')\n",
        "    cleantext=re.sub(clean,'',text)\n",
        "    return cleantext\n",
        "\n",
        "# first round of cleaning\n",
        "def clean_text1(text):\n",
        "    text=text.lower()\n",
        "    text=re.sub('\\[.*?\\]','',text)\n",
        "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
        "    text=re.sub('\\w*\\d\\w*','',text)\n",
        "    return text\n",
        "\n",
        "# second round of cleaning\n",
        "def clean_text2(text):\n",
        "    text=re.sub('[''\"\",,,]','',text)\n",
        "    text=re.sub('\\n','',text)\n",
        "    return text\n",
        "\n",
        "cleaned_html=lambda x:clean_html(x)\n",
        "cleaned1=lambda x:clean_text1(x)\n",
        "cleaned2=lambda x:clean_text2(x)\n",
        "\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned_html))\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned1))\n",
        "data['review']=pd.DataFrame(data.review.apply(cleaned2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Po7GWPxaVF"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3oxLEyJ_IvCz"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
        "tokenizer.fit_on_texts(data['review'].values)\n",
        "X = tokenizer.texts_to_sequences(data['review'].values)\n",
        "X = pad_sequences(X,maxlen=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyu95uejxaVG",
        "outputId": "64bef470-ff89-487c-9ba2-63ea2873215d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 600, 128)          640000    \n",
            "                                                                 \n",
            " spatial_dropout1d_3 (Spati  (None, 600, 128)          0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 600, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 300, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 19200)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               4915456   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5580610 (21.29 MB)\n",
            "Trainable params: 5580610 (21.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, SpatialDropout1D, Embedding, Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(5000, 128, input_length=X.shape[1]))  # Embedding layer\n",
        "model_cnn.add(SpatialDropout1D(0.4))  # Spatial Dropout for regularization\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))  # Convolutional Layer 1\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))  # Pooling Layer 1\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))  # Convolutional Layer 2\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))  # Pooling Layer 2\n",
        "model_cnn.add(Flatten())  # Flatten layer\n",
        "model_cnn.add(Dense(256, activation='relu'))  # Fully Connected Layer\n",
        "model_cnn.add(Dropout(0.5))  # Dropout for regularization\n",
        "model_cnn.add(Dense(128, activation='relu'))  # Hidden Layer\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model_cnn.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uRaASZHxaVH"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1O9Lc3fOxaVH"
      },
      "outputs": [],
      "source": [
        "Y=pd.get_dummies(data['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = tts(X,Y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hcs8k1kxaVI"
      },
      "source": [
        "## Running the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHvTFFdexaVI",
        "outputId": "5780402c-ef09-435d-f52c-cfbca36957e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 201s 319ms/step - loss: 0.3790 - accuracy: 0.8130 - val_loss: 0.2541 - val_accuracy: 0.8982\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 197s 315ms/step - loss: 0.2327 - accuracy: 0.9100 - val_loss: 0.2544 - val_accuracy: 0.9001\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 200s 320ms/step - loss: 0.1912 - accuracy: 0.9263 - val_loss: 0.2547 - val_accuracy: 0.9012\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 192s 307ms/step - loss: 0.1488 - accuracy: 0.9435 - val_loss: 0.2855 - val_accuracy: 0.8978\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 193s 309ms/step - loss: 0.1108 - accuracy: 0.9586 - val_loss: 0.3163 - val_accuracy: 0.8929\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 194s 310ms/step - loss: 0.0806 - accuracy: 0.9697 - val_loss: 0.3575 - val_accuracy: 0.8921\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 202s 323ms/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 0.4260 - val_accuracy: 0.8904\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 203s 324ms/step - loss: 0.0468 - accuracy: 0.9831 - val_loss: 0.4522 - val_accuracy: 0.8863\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 194s 310ms/step - loss: 0.0412 - accuracy: 0.9851 - val_loss: 0.4589 - val_accuracy: 0.8859\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 197s 315ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.4832 - val_accuracy: 0.8868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78fc7dfa62f0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "batch_size = 64\n",
        "model_cnn.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test,Y_test), verbose = True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}